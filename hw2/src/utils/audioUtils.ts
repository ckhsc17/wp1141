// éŸ³æ•ˆå·¥å…·é¡
class AudioUtils {
  private static instance: AudioUtils;
  private audioContext: AudioContext | null = null;

  private constructor() {
    // ç¢ºä¿åœ¨ç€è¦½å™¨ç’°å¢ƒä¸­åˆå§‹åŒ–
    if (typeof window !== 'undefined') {
      this.audioContext = new (window.AudioContext || (window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext)();
    }
  }

  public static getInstance(): AudioUtils {
    if (!AudioUtils.instance) {
      AudioUtils.instance = new AudioUtils();
    }
    return AudioUtils.instance;
  }

  // å‰µå»ºç¯€æ‹å™¨è²éŸ³
  public createMetronomeClick(frequency: number = 800, duration: number = 0.1): void {
    if (!this.audioContext) return;

    const oscillator = this.audioContext.createOscillator();
    const gainNode = this.audioContext.createGain();

    oscillator.connect(gainNode);
    gainNode.connect(this.audioContext.destination);

    oscillator.frequency.setValueAtTime(frequency, this.audioContext.currentTime);
    oscillator.type = 'square';

    gainNode.gain.setValueAtTime(0, this.audioContext.currentTime);
    gainNode.gain.linearRampToValueAtTime(0.3, this.audioContext.currentTime + 0.01);
    gainNode.gain.linearRampToValueAtTime(0.001, this.audioContext.currentTime + duration);

    oscillator.start(this.audioContext.currentTime);
    oscillator.stop(this.audioContext.currentTime + duration);
  }

  // å‰µå»ºæŒ‰éµéŸ³æ•ˆ
  public createKeyPressSound(isCorrect: boolean): void {
    if (!this.audioContext) return;

    const oscillator = this.audioContext.createOscillator();
    const gainNode = this.audioContext.createGain();

    oscillator.connect(gainNode);
    gainNode.connect(this.audioContext.destination);

    // æ­£ç¢ºæ™‚æ’­æ”¾é«˜éŸ³ï¼ŒéŒ¯èª¤æ™‚æ’­æ”¾ä½éŸ³
    const frequency = isCorrect ? 1000 : 300;
    const duration = 0.15;

    oscillator.frequency.setValueAtTime(frequency, this.audioContext.currentTime);
    oscillator.type = isCorrect ? 'sine' : 'sawtooth';

    gainNode.gain.setValueAtTime(0, this.audioContext.currentTime);
    gainNode.gain.linearRampToValueAtTime(0.4, this.audioContext.currentTime + 0.01);
    gainNode.gain.linearRampToValueAtTime(0.001, this.audioContext.currentTime + duration);

    oscillator.start(this.audioContext.currentTime);
    oscillator.stop(this.audioContext.currentTime + duration);
  }

  // å‰µå»ºéŸ³ç¬¦æ’­æ”¾è²éŸ³ (ç”¨æ–¼ç·´ç¿’æ¨¡å¼)
  public createNoteSound(noteFrequency: number, duration: number = 0.5): void {
    if (!this.audioContext) return;

    const oscillator = this.audioContext.createOscillator();
    const gainNode = this.audioContext.createGain();

    oscillator.connect(gainNode);
    gainNode.connect(this.audioContext.destination);

    oscillator.frequency.setValueAtTime(noteFrequency, this.audioContext.currentTime);
    oscillator.type = 'sine';

    gainNode.gain.setValueAtTime(0, this.audioContext.currentTime);
    gainNode.gain.linearRampToValueAtTime(0.3, this.audioContext.currentTime + 0.05);
    gainNode.gain.linearRampToValueAtTime(0.001, this.audioContext.currentTime + duration);

    oscillator.start(this.audioContext.currentTime);
    oscillator.stop(this.audioContext.currentTime + duration);
  }

  // æ¢å¾©éŸ³é »ä¸Šä¸‹æ–‡ (ç”¨æˆ¶äº¤äº’å¾Œ) - æ”¹é€²ç‰ˆæœ¬
  public async resumeAudioContext(): Promise<void> {
    if (this.audioContext && this.audioContext.state === 'suspended') {
      try {
        await this.audioContext.resume();
        console.log('ğŸ”Š AudioContext resumed successfully, state:', this.audioContext.state);
      } catch (error) {
        console.error('âŒ Failed to resume AudioContext:', error);
        throw error;
      }
    } else if (this.audioContext) {
      console.log('ğŸ”Š AudioContext state:', this.audioContext.state);
    }
  }

  // æª¢æŸ¥éŸ³é »ä¸Šä¸‹æ–‡ç‹€æ…‹
  public getAudioContextState(): string {
    return this.audioContext?.state || 'no-context';
  }

  // åˆå§‹åŒ–éŸ³é »ä¸Šä¸‹æ–‡ï¼ˆç”¨æ–¼ç”¨æˆ¶é¦–æ¬¡äº¤äº’ï¼‰
  public async initializeAudioContext(): Promise<void> {
    if (!this.audioContext) {
      try {
        this.audioContext = new (window.AudioContext || (window as unknown as { webkitAudioContext: typeof AudioContext }).webkitAudioContext)();
        console.log('ğŸ”Š AudioContext created, state:', this.audioContext.state);
      } catch (error) {
        console.error('âŒ Failed to create AudioContext:', error);
        throw error;
      }
    }
    
    if (this.audioContext.state === 'suspended') {
      await this.audioContext.resume();
      console.log('ğŸ”Š AudioContext resumed during initialization, state:', this.audioContext.state);
    }
  }

  // æª¢æŸ¥éŸ³é »æ˜¯å¦å¯ç”¨
  public isAudioAvailable(): boolean {
    return this.audioContext !== null && this.audioContext.state === 'running';
  }

  // æ¸¬è©¦éŸ³é »æ’­æ”¾ï¼ˆç”¨æ–¼èª¿è©¦ï¼‰
  public async testAudio(): Promise<void> {
    try {
      await this.resumeAudioContext();
      this.createKeyPressSound(true);
      console.log('ğŸ”Š Audio test completed');
    } catch (error) {
      console.error('âŒ Audio test failed:', error);
    }
  }
}

// éŸ³ç¬¦åˆ°é »ç‡çš„æ˜ å°„
export const NOTE_FREQUENCIES: { [key: string]: number } = {
  'C': 261.63,
  'D': 293.66,
  'E': 329.63,
  'F': 349.23,
  'G': 392.00,
  'A': 440.00,
  'B': 493.88,
};

export default AudioUtils;